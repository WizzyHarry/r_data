library(readxl)
df <- read_excel("C:/Users/Keith/MS_BA-Sem1/qmb/assign_2/Launch Excel.xlsx", sheet = "Data")
df <- df[, c("Y", paste0("X", 1:10))]
df$Y <- as.factor(df$Y)
train_data <- df[1:1000, ]
test_data <- df[1001:1500, ]
model <- glm(Y ~ ., data = train_data, family = binomial)
summary_model <- summary(model)
print(summary_model$coefficients)
coefs <- summary_model$coefficients
coefs[, "Pr(>|z|)"] <- format(coefs[, "Pr(>|z|)"], scientific = FALSE, digits = 6)
print(coefs)
significant <- summary_model$coefficients[, "Pr(>|z|)"] < 0.05
print(summary_model$coefficients[significant, , drop = FALSE])
cat("\nAIC:", AIC(model), "\n")
cat("BIC:", BIC(model), "\n")
train_prob <- predict(model, type = "response")
train_pred <- ifelse(train_prob >= 0.5, 1, 0)
test_prob <- predict(model, newdata = test_data, type = "response")
test_pred <- ifelse(test_prob >= 0.5, 1, 0)
train_actual <- as.numeric(as.character(train_data$Y))
train_cm <- table(Predicted = train_pred, Actual = train_actual)
train_accuracy <- sum(diag(train_cm)) / sum(train_cm)
print(train_cm)
cat(sprintf("Training Accuracy: %.2f%%\n", train_accuracy * 100))
test_actual <- as.numeric(as.character(test_data$Y))
test_cm <- table(Predicted = test_pred, Actual = test_actual)
test_accuracy <- sum(diag(test_cm)) / sum(test_cm)
print(test_cm)
cat(sprintf("Holdout Accuracy: %.2f%%\n", test_accuracy * 100))
save.image("C:\\Users\\Keith\\MS_BA-Sem1\\qmb\\assign_2\\P2Q1")
q()
library(readxl)
library(MASS)
library(stats)
df <- read_excel("C:/Users/Keith/MS_BA-Sem1/qmb/assign_2/Launch Excel.xlsx", sheet = "Data")
df <- df[, c("Y", paste0("X", 1:10))]
df$Y <- as.factor(df$Y)
train <- df[1:1000, ]
holdout <- df[1001:1500, ]
lda_model <- lda(Y ~ ., data = train)
print(lda_model$scaling)
cat("\n=== Predictor Significance via ANOVA (Î± = 0.05) ===\n")
p_values <- sapply(paste0("X", 1:10), function(var) {
anova_result <- summary(aov(as.formula(paste(var, "~ Y")), data = train))
anova_result[[1]]$`Pr(>F)`[1]
})
significance <- data.frame(Predictor = paste0("X", 1:10), p_value = p_values)
significance$Significant <- significance$p_value < 0.05
print(significance)
train_pred <- predict(lda_model, newdata = train)$class
train_cm <- table(Predicted = train_pred, Actual = train$Y)
train_acc <- sum(diag(train_cm)) / sum(train_cm)
holdout_pred <- predict(lda_model, newdata = holdout)$class
holdout_cm <- table(Predicted = holdout_pred, Actual = holdout$Y)
holdout_acc <- sum(diag(holdout_cm)) / sum(holdout_cm)
cat("\n=== Training Confusion Matrix ===\n")
print(train_cm)
cat(sprintf("Training Accuracy: %.2f%%\n", train_acc * 100))
cat("\n=== Holdout Confusion Matrix ===\n")
print(holdout_cm)
cat(sprintf("Holdout Accuracy: %.2f%%\n", holdout_acc * 100))
q()
save.image("C:\\Users\\Keith\\MS_BA-Sem1\\qmb\\assign_2\\p2q1Inc")
q()
install.packages('leaps')
library(leaps)
library(readxl)
df <- read_excel("C:/Users/Keith/MS_BA-Sem1/qmb/assign_2/Empathy Excel.xlsx", sheet = "Empathy")
response <- "davi3"
predictors <- setdiff(names(df), response)
formula <- as.formula(paste(response, "~", paste(predictors, collapse = "+")))
model_cp <- regsubsets(formula, data = df, nvmax = length(predictors), method = "forward")
summary_cp <- summary(model_cp)
best_index <- which.min(summary_cp$cp)
best_predictors <- names(coef(model_cp, best_index))[-1]
cat("=== Best Forward Selection Model Using Mallows' Cp ===\n")
cat("Number of Predictors Selected:", best_index, "\n")
cat("Selected Predictors:\n")
print(best_predictors)
cat(sprintf("\nR-squared: %.4f", summary_cp$rsq[best_index]))
cat(sprintf("\nMallows' Cp: %.4f\n", summary_cp$cp[best_index]))
q()
library('MASS')
data <- read.excel("C:/Users/Keith/MS_BA-Sem1/qmb/assign_2/Launch Excel.xlsx", sheet =
library(MASS)
library(readxl)
library(caret)
data <- read_excel("C:/Users/Keith/MS_BA-Sem1/qmb/assign_2/Launch Excel.xlsx", sheet = "Data")
data <- data[, c("Y", "X1", "X2", "X3", "X4", "X5", "X6", "X7", "X8", "X9", "X10")]
train <- data[1:1000, ]
test <- data[1001:1500, ]
lda_model <- lda(Y ~ ., data = train)
train_preds <- predict(lda_model, newdata = train)
test_preds <- predict(lda_model, newdata = test)
cost_fn <- 3
cost_fp <- 1
custom_cutoff <- 1 / (1 + cost_fn / cost_fp)
train_class <- ifelse(train_preds$posterior[, "1"] > custom_cutoff, 1, 0)
test_class <- ifelse(test_preds$posterior[, "1"] > custom_cutoff, 1, 0)
cat("\nTraining Confusion Matrix:\n")
train_cm <- table(Predicted = train_class, Actual = train$Y)
print(train_cm)
cat("\nHoldout Confusion Matrix:\n")
test_cm <- table(Predicted = test_class, Actual = test$Y)
print(test_cm)
train_fp <- ifelse(!is.na(train_cm["1", "0"]), train_cm["1", "0"], 0)
train_fn <- ifelse(!is.na(train_cm["0", "1"]), train_cm["0", "1"], 0)
train_cost <- cost_fn * train_fn + cost_fp * train_fp
test_fp <- ifelse(!is.na(test_cm["1", "0"]), test_cm["1", "0"], 0)
test_fn <- ifelse(!is.na(test_cm["0", "1"]), test_cm["0", "1"], 0)
test_cost <- cost_fn * test_fn + cost_fp * test_fp
train_acc <- mean(train_class == train$Y)
test_acc <- mean(test_class == test$Y)
cat("\nTraining Accuracy:", round(train_acc * 100, 2), "%")
cat("\nTraining Misclassification Cost:", train_cost)
cat("\n\nHoldout Accuracy:", round(test_acc * 100, 2), "%")
cat("\nHoldout Misclassification Cost:", test_cost)
q()
rm(list = ls(envir = globalenv()), envir = globalenv());
if(!is.null(dev.list())) dev.off(); gc(); cat("\014")
setwd(r"C:\Users\Keith\github\portfolio\lis4369\a5")
setwd(dirname(getwd()))
setwd(choose.dir())
setwd(choose.dir())
setwd(choose.dir(caption = "Select your working directory"))
library(rstudioapi)
install.packages('rstudioapi')
library(rstudioapi)
setwd(selectDirectory(caption = "Select your working directory"))
installed.packages()
user_installed <- setdiff(
rownames(installed.packages()),
rownames(installed.packages(priority = c("base", "recommended")))
)
as.data.frame(user_installed)
update.packages()
update.packages()
data()
getSymbols("AAPL")
barChart(AAPL)
install.packages("quantmod")
library(quantmod)
getSymbols("AAPL")
View(AAPL)
barChart(AAPL)
barChart(AAPL["2007-04-01::2024-12-31"])
setwd(selectDirectory(caption = "Select your working directory"))
mtcars
head(mtcars)
tail(mtcars, 10)
str(mtcars)
cor(mtcars)
mean(mtcars$mpg, na.rm = TRUE)
choose(15,4)
names(mtcars)
mtcars$mpg>20
mtcars[mtcars$mpg>20,]
mtcars[mtcars$mpg>20,c("mpg","hp","cyl")]
mtcars[,2:4]
subset(mtcars, mpg>20, c("mpg","cyl"))
subset(mtcars, , c("mpg","hp"))
filter(mtcars, mpg>20)
filter(mtcars, mtcars$mpg>20)
filter(mtcars, mpg>20)
library(dplyr)
filter(mtcars, mpg>20)
select(mtcars, mpg, hp)
table(trees$cut)
plot(mtcars$disp, mtcars$mpg)
plot(mtcars$disp, mtcars$mpg, xlab="Engine displacement",
ylab="mpg", main="is this title?")
plot(mtcars$disp, mtcars$mpg, xlab="Engine Displacement",
ylab="MPG", main="MPG v. Displacement")
?par
library(ggplot2)
qplot(disp, mpg, data=mtcars)
qplot(disp, mpg, ylim=c(0,35), data=mtcars)
ggplot(cty, hwy, data=mpg, geom="jitter")
str(mtcars)
str(mtcars$mpg)
ggplot(mpg, aes(x = cty, y = hwy)) +
geom_jitter()
ggplot(pressure, aes(x=temperature, y=pressure)) + geom_line()
ggplot(pressure, aes(x=temperature, y=pressure)) + geom_line() + geom_point()
barplot(BOD$demand)
barplot(BOD$demand, main="Graph of demand"
, names.arg = BOD$Time)
data()
cylcount <- table(mtcars$cyl)
barplot(cylcount)
qplot(mtcars$cyl)
ggplot(mtcars, aes(factor(cyl))) + geom_bar()
boxplot(mtcars$mpg)
mycolors <- heat.colors(3)
mrecolors <- rainbow(6)
ggplot(mtcars, aes(x=factor(cyl))) + geom_bar(fill=mycolors)
barplot(BOD$demand, col=mrecolors)
load("C:/Users/Keith/github/portfolio/lis4369/a5/.RData")
View(titanic)
View(titanic_no_missing_data)
rm(list = ls(envir = globalenv()), envir = globalenv());
if(!is.null(dev.list())) dev.off(); gc(); cat("\014")
setwd(selectDirectory(caption = "Select your working directory"))
a <- 9
a + 5
b <- sqrt(a)
b
c <- c(1,2,5.3,6,-2.4)
print(c)
c
typeof(c)
is.list(c)
is.vector(c)
d <- c("one", "two", "three")
is.list(d)
typeof(d)
e <- c(TRUE,TRUE,TRUE,FALSE,TRUE,FALSE)
e
typeof(e)
d[1]
my_str <- "Hello World!"
typeof(my_str)
min(c)
mean(c)
rm(list = ls(envir = globalenv()), envir = globalenv());
if(!is.null(dev.list())) dev.off(); gc(); cat("\014")
url = "https://raw.github.com/vincentarelbundock/Rdatasets/master/csv/Stat2Data/Titanic.csv"
titanic <- read.csv(file=url,head=TRUE,sep=",")
View(titanic)
summary(titanic)
dir()
getwd()
names(titanic)
titanic$Name
str(titanic)
attributes(titanic)
ls()
mean(titanic$Age)
mean(titanic$Age, na.rm=TRUE)
quantile(titanic$Age, na.rm=TRUE)
min(titanic$Age, na.rm=TRUE)
max(titanic$Age, na.rm=TRUE)
var(titanic$Age, na.rm=TRUE)
sd(titanic$Age, na.rm=TRUE)
summary(titanic$Age, na.rm=TRUE)
titanic[!complete.cases(titanic),]
titanic_no_missing_data <- na.omit(titanic)
titanic_no_missing_data
View(titanic_no_missing_data)
stripchart(titanic_no_missing_data$Age)
boxplot(titanic_no_missing_data$Age)
boxplot(titanic_no_missing_data$Age,
main="Distribution of Titanic Passengers Ages",
xlab="Ages",
horizontal=TRUE)
plot(titanic_no_missing_data$Age,titanic_no_missing_data$Survived,
main="Relationship Between Ages and Survival",
xlab="Age",
ylab="Survived")
plot(jitter(titanic_no_missing_data$Age),jitter(titanic_no_missing_data$Survived),
main="Relationship Between Ages and Survival",
xlab="Age",
ylab="Survived",
col = ifelse(titanic_no_missing_data$Survived == 1, "blue", "red"),
pch = 20)
library("ggplot2")
ggplot(titanic_no_missing_data, aes(x=Age, y=Survived)) +
geom_jitter(aes(color = as.factor(Survived)), width=0.3, height=0.1, size=2) +
labs(title = "Relationship Between Ages and Survival",
x = "Age",
y = "Survived") +
scale_color_manual(values = c("red", "blue"), labels = c("Not Survived", "Survived")) +
theme_minimal()
rm(list = ls(envir = globalenv()), envir = globalenv());
if(!is.null(dev.list())) dev.off(); gc(); cat("\014")
